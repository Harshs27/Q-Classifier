function mainQ(filename)
  % code for Q Classifier.
  % by Harsh Shrivastava, IITKGP, XRCI

  %initialising constants
  iter1 = 100; % number of iterations
  alpha_theta = 3.2; % the learning rate of parameter 'theta'
  alpha_sigma = 0.3;% the learning rate of parameter 'sigma'
  alpha_rho = 0.00; % learning rate of parameter 'rho'
  Influence_points = 150; % find a method to automatically the optimum number of clusters [maybe by affinity propagation clustering...]
  J_thresh = 0.001; % threshold for iterations for penalty

  data = load(filename);
%  randomly shuffle the dataset to mix the 1's and 0's 
%  data_shuffle = data(randperm(size(data, 1)), :);
%  data = data_shuffle;
  X = data(:, 2:end);
  y = data(:, 1);
% extracting the filepath, name and extension
  [path, name, ext] = fileparts(filename);
  [m n] = size(X); % m = number of examples; n = number of features
  % normalize the data
  [Xnorm MINnorm MAXnorm] = normalize_data(X); % create the function normalize

% initialisation of L using the K-means method on the data || Also try out using the affinity propagation cluster finder...

  fprintf('Finding the landmark points using the K-means cluster centers...\n');
  L = 0;
  [IDX L] = kmeans(Xnorm, Influence_points);
  disp(L);
  fprintf('Landmark points initialised! \n');
  [l n_landmark] = size(L);% l = number of landmark points chosen
  
  fprintf('The total number of landmarks chosen = %d\n', l);
  if n ~= n_landmark,
    fprintf('error : the dimensions of the landmark points and input do not match !! \n ');
  end

  % Initialize the Sigma matrix with the rho and Ifac values.
  Sigma = zeros(n, n);
  rho = zeros(n, n);

% generate theta as a column vector...
  fprintf('Initialising the theta parameter by the value 1/(l+1) where l = number of Influence points\n');
  theta =  gen_random_vector(l+1, 1/(l+1), 1/(l+1));
% initialization of the sigma values. 
  fprintf('Initialising the Ifac values by calculating the variance of the input data.\n');
  sigma = zeros(n, 1);

% finding the mean of the Landmark points generated by cluster finding algorithms.  
  fprintf('Initialising the rho coefficients by using the pearson coefficients. \n');
  mu_L = mean(L);
  fprintf('Displaying the mu_L\n');
  disp(mu_L);

  for j = 1:1:n, 
    for i = 1:1:m,
      sigma(j) = sigma(j)+((Xnorm(i, j)-mu_L(j))^2);
    end
    sigma(j) = sqrt(sigma(j)/m);
  end
  disp(sigma);


  % initialising the rho matrix values... 
  rho = zeros(n, n);
  for p=1:1:n, 
    for q = p:1:n, 
      for i = 1:1:m,
          rho(p, q) = rho(p, q) + (Xnorm(i, p) - mu_L(p))*(Xnorm(i, q)-mu_L(q));
      end
      rho(p, q) = rho(p, q)/ (m*sigma(p)*sigma(q));
      rho(q, p) = rho(p, q);
    end
  end
  disp(rho);
% initialising the Sigma Matrix values...
  fprintf('Initialising the Sigma matrix...\n')
  for p=1:1:n,
    for q=1:1:n,
      Sigma(p, q)= rho(p, q)*sigma(p)*sigma(q);
    end
  end
  disp(Sigma);
  fprintf('Displaying the initial parameters\n');
  [F Sigma inv_Sigma] = ImpactQ(Xnorm, L, rho, sigma, m, n, l);
  % F dimesions should be (M x L)
  fprintf('After the test Influence calculation\n');
%  disp(Sigma);
%  disp(F);
  [theta sigma rho J] = trainQ(F, Xnorm, L, y, rho, sigma, m, n, l, theta, iter1, alpha_theta, alpha_sigma, alpha_rho, MINnorm, MAXnorm, name, J_thresh);
  fprintf('Final theta value\n');
  disp(theta);
  
% Determining the threshold from the training datasets
  fprintf('Determining the threshold value from the training dataset\n');
%  [th] = ThQ(Xnorm, L, rho, sigma, m, n, l, theta, y);
  [th] = ThwQ(Xnorm, L, rho, sigma, m, n, l, theta, y);
  
  % saving variables to be loaded in predict.m for classifying
  save(strcat(name, '_param.mat'), 'MINnorm','MAXnorm', 'rho', 'sigma', 'theta', 'L', 'J', 'th');
end

